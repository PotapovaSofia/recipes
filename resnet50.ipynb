{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filters = ['Original', 'Gingham', 'Helena', 'Kelvin', 'Ludwig', 'Moon', 'Slumber', 'Ginza', 'Juno', 'Lo-Fi', 'Maven', 'Toaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "\n",
    "def build_simple_block(incoming_layer, names,\n",
    "                       num_filters, filter_size, stride, pad,\n",
    "                       use_bias=False, nonlin=rectify):\n",
    "    names = list(names)\n",
    "    net = []\n",
    "    net.append((\n",
    "            names[0],\n",
    "            ConvLayer(incoming_layer, num_filters, filter_size, stride, pad,\n",
    "                      flip_filters=False, nonlinearity=None) if use_bias\n",
    "            else ConvLayer(incoming_layer, num_filters, filter_size, stride, pad, b=None,\n",
    "                           flip_filters=False, nonlinearity=None)\n",
    "        ))\n",
    "\n",
    "    net.append((\n",
    "            names[1],\n",
    "            BatchNormLayer(net[-1][1])\n",
    "        ))\n",
    "    if nonlin is not None:\n",
    "        net.append((\n",
    "            names[2],\n",
    "            NonlinearityLayer(net[-1][1], nonlinearity=nonlin)\n",
    "        ))\n",
    "\n",
    "    return dict(net), net[-1][0]\n",
    "\n",
    "\n",
    "def build_residual_block(incoming_layer, ratio_n_filter=1.0, ratio_size=1.0, has_left_branch=False,\n",
    "                         upscale_factor=4, ix=''):\n",
    "    simple_block_name_pattern = ['res%s_branch%i%s', 'bn%s_branch%i%s', 'res%s_branch%i%s_relu']\n",
    "\n",
    "    net = {}\n",
    "\n",
    "    # right branch\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        incoming_layer, map(lambda s: s % (ix, 2, 'a'), simple_block_name_pattern),\n",
    "        int(lasagne.layers.get_output_shape(incoming_layer)[1]*ratio_n_filter), 1, int(1.0/ratio_size), 0)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'b'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1], 3, 1, 1)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'c'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1]*upscale_factor, 1, 1, 0,\n",
    "        nonlin=None)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    right_tail = net[last_layer_name]\n",
    "    left_tail = incoming_layer\n",
    "\n",
    "    # left branch\n",
    "    if has_left_branch:\n",
    "        net_tmp, last_layer_name = build_simple_block(\n",
    "            incoming_layer, map(lambda s: s % (ix, 1, ''), simple_block_name_pattern),\n",
    "            int(lasagne.layers.get_output_shape(incoming_layer)[1]*4*ratio_n_filter), 1, int(1.0/ratio_size), 0,\n",
    "            nonlin=None)\n",
    "        net.update(net_tmp)\n",
    "        left_tail = net[last_layer_name]\n",
    "\n",
    "    net['res%s' % ix] = ElemwiseSumLayer([left_tail, right_tail], coeffs=1)\n",
    "    net['res%s_relu' % ix] = NonlinearityLayer(net['res%s' % ix], nonlinearity=rectify)\n",
    "\n",
    "    return net, 'res%s_relu' % ix\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    sub_net, parent_layer_name = build_simple_block(\n",
    "        net['input'], ['conv1', 'bn_conv1', 'conv1_relu'],\n",
    "        64, 7, 2, 3, use_bias=True)\n",
    "    net.update(sub_net)\n",
    "    net['pool1'] = PoolLayer(net[parent_layer_name], pool_size=3, stride=2, pad=0, mode='max', ignore_border=False)\n",
    "    block_size = list('abc')\n",
    "    parent_layer_name = 'pool1'\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1, 1, True, 4, ix='2%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='2%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcd')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='3%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='3%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcdef')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='4%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='4%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abc')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='5%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='5%s' % c)\n",
    "        net.update(sub_net)\n",
    "    net['pool5'] = PoolLayer(net[parent_layer_name], pool_size=7, stride=1, pad=0,\n",
    "                             mode='average_exc_pad', ignore_border=False)\n",
    "    net['fc1000'] = DenseLayer(net['pool5'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc1000'], nonlinearity=softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = pickle.load(open('resnet50.pkl', 'rb'), encoding='latin1')\n",
    "net = build_model()\n",
    "lasagne.layers.set_all_param_values(net['prob'], weights['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode=self.mode,\n",
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode=self.mode,\n",
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode=self.mode,\n"
     ]
    }
   ],
   "source": [
    "inpt = T.tensor4()\n",
    "prep_fn = theano.function([inpt], lasagne.layers.get_output(net['pool5'], inpt, deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nnet = {}\n",
    "nnet['input'] = InputLayer([None, 2048])\n",
    "nnet['dense'] = lasagne.layers.DenseLayer(nnet['input'], num_units=1024)\n",
    "nnet['prob'] = lasagne.layers.DenseLayer(nnet['dense'], num_units=len(filters),\n",
    "                                         nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target = T.ivector()\n",
    "inpt = T.matrix()\n",
    "\n",
    "pred = lasagne.layers.get_output(nnet['prob'], inpt, deterministic=False)\n",
    "pred_det = lasagne.layers.get_output(nnet['prob'], inpt, deterministic=True)\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(pred, target).mean()\n",
    "loss += 1e-5 * lasagne.regularization.regularize_network_params(nnet['prob'], lasagne.regularization.l2)\n",
    "loss_det = lasagne.objectives.categorical_crossentropy(pred_det, target).mean()\n",
    "\n",
    "acc = lasagne.objectives.categorical_accuracy(pred_det, target).mean()\n",
    "\n",
    "params = []\n",
    "for k, v in nnet.items():\n",
    "    params.extend(v.get_params())\n",
    "\n",
    "updates = lasagne.updates.adam(loss, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = theano.function([inpt, target], [loss], updates=updates)\n",
    "predict_prob = theano.function([inpt], [pred_det])\n",
    "pred_acc = theano.function([inpt, target], [acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "H, W = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import skimage.color\n",
    "\n",
    "def preprocess(im):\n",
    "    im = skimage.color.gray2rgb(im)\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    im = im[::-1, :, :]\n",
    "    return (im - weights['mean_image']).astype(np.float32)\n",
    "\n",
    "def crop_center(img, H=112, W=112):\n",
    "    h,w = img.shape[:2]\n",
    "    hc, wc = h // 2, w // 2\n",
    "    return img[hc - H: hc + H, wc - W : wc + W]\n",
    "\n",
    "def augment(x):\n",
    "    return [x[:H, :W], x[-H:, -W:], x[:H, -W:], x[-H:, :W], crop_center(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def myprocess(im):\n",
    "    return prep_fn(list(map(preprocess, augment(im))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 897/897 [01:59<00:00,  7.47it/s]\n",
      "100%|██████████| 897/897 [01:58<00:00,  7.55it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.49it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.46it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.53it/s]\n",
      "100%|██████████| 897/897 [02:03<00:00,  7.29it/s]\n",
      "100%|██████████| 897/897 [02:03<00:00,  7.26it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.54it/s]\n",
      "100%|██████████| 897/897 [02:03<00:00,  7.31it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.52it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.54it/s]\n",
      "100%|██████████| 897/897 [01:59<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for fi, f in enumerate(filters):\n",
    "    for i in tqdm(range(100, 997)):\n",
    "        try:\n",
    "            nx = myprocess(plt.imread(f + '/' + str(i) + '.jpg'))\n",
    "            if i < 200:\n",
    "                X_test.extend(nx)\n",
    "                y_test.extend([fi] * len(nx))\n",
    "            else:\n",
    "                X_train.extend(nx)\n",
    "                y_train.extend([fi] * len(nx))\n",
    "        except:\n",
    "            pass\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump((X_train, X_test, y_train, y_test), open('traintestdata.pkl', 'wb'))\n",
    "X_train, X_test, y_train, y_test  = pickle.load(open('traintestdata.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    indices = np.arange(len(inputs))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    start_idx = 0\n",
    "    for start_idx in range(0, len(inputs), batchsize):\n",
    "        excerpt = indices[start_idx: min(len(inputs), start_idx + batchsize)]\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "err_log = []\n",
    "val_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113\ttook 0.8366317749023438\ttrain: 1.7569742525617282\tval acc: 0.6993333333333333\n",
      "epoch: 114\ttook 0.7890450954437256\ttrain: 0.8205591601630052\tval acc: 0.7475\n",
      "epoch: 115\ttook 0.7291712760925293\ttrain: 0.6430496374766032\tval acc: 0.761\n",
      "epoch: 116\ttook 0.7265677452087402\ttrain: 0.5465609511981407\tval acc: 0.7815\n",
      "epoch: 117\ttook 0.7236247062683105\ttrain: 0.46947560645639896\tval acc: 0.7838333333333334\n",
      "epoch: 118\ttook 0.7228283882141113\ttrain: 0.4130351065347592\tval acc: 0.7915\n",
      "epoch: 119\ttook 0.7156577110290527\ttrain: 0.3669953513890505\tval acc: 0.7906666666666667\n",
      "epoch: 120\ttook 0.7154340744018555\ttrain: 0.32051418349146843\tval acc: 0.7945000000000001\n",
      "epoch: 121\ttook 0.7226624488830566\ttrain: 0.2844625298554699\tval acc: 0.7933333333333333\n",
      "epoch: 122\ttook 0.7160594463348389\ttrain: 0.24436376926799616\tval acc: 0.8016666666666666\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    err = 0\n",
    "    batches = 0\n",
    "    t = time.time()\n",
    "    for X_batch, y_batch in iterate_minibatches(X_train, y_train, 1000, True):\n",
    "        err += train(X_batch, y_batch)[0]\n",
    "        batches += 1\n",
    "    err_log.append(err / batches)\n",
    "    \n",
    "    err = 0\n",
    "    batches = 0\n",
    "    for X_batch, y_batch in iterate_minibatches(X_test, y_test, 500, True):\n",
    "        err += pred_acc(X_batch, y_batch)[0]\n",
    "        batches += 1\n",
    "    val_log.append(err / batches)\n",
    "    print('epoch: {}\\ttook {}\\ttrain: {}\\tval acc: {}'.format(epoch, time.time() - t, err_log[-1], val_log[-1]))\n",
    "    if val_log[-1] > 0.801:\n",
    "        break\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnet['dense'].input_layer = net['pool5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'values':lasagne.layers.get_all_param_values(nnet['prob']),\n",
    "       'mean_image': weights['mean_image']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(data, open('resnet50_final.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "import skimage.color\n",
    "\n",
    "def build_simple_block(incoming_layer, names,\n",
    "                       num_filters, filter_size, stride, pad,\n",
    "                       use_bias=False, nonlin=rectify):\n",
    "    names = list(names)\n",
    "    net = []\n",
    "    net.append((\n",
    "            names[0],\n",
    "            ConvLayer(incoming_layer, num_filters, filter_size, stride, pad,\n",
    "                      flip_filters=False, nonlinearity=None) if use_bias\n",
    "            else ConvLayer(incoming_layer, num_filters, filter_size, stride, pad, b=None,\n",
    "                           flip_filters=False, nonlinearity=None)\n",
    "        ))\n",
    "\n",
    "    net.append((\n",
    "            names[1],\n",
    "            BatchNormLayer(net[-1][1])\n",
    "        ))\n",
    "    if nonlin is not None:\n",
    "        net.append((\n",
    "            names[2],\n",
    "            NonlinearityLayer(net[-1][1], nonlinearity=nonlin)\n",
    "        ))\n",
    "\n",
    "    return dict(net), net[-1][0]\n",
    "\n",
    "\n",
    "def build_residual_block(incoming_layer, ratio_n_filter=1.0, ratio_size=1.0, has_left_branch=False,\n",
    "                         upscale_factor=4, ix=''):\n",
    "    simple_block_name_pattern = ['res%s_branch%i%s', 'bn%s_branch%i%s', 'res%s_branch%i%s_relu']\n",
    "\n",
    "    net = {}\n",
    "\n",
    "    # right branch\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        incoming_layer, map(lambda s: s % (ix, 2, 'a'), simple_block_name_pattern),\n",
    "        int(lasagne.layers.get_output_shape(incoming_layer)[1]*ratio_n_filter), 1, int(1.0/ratio_size), 0)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'b'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1], 3, 1, 1)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'c'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1]*upscale_factor, 1, 1, 0,\n",
    "        nonlin=None)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    right_tail = net[last_layer_name]\n",
    "    left_tail = incoming_layer\n",
    "\n",
    "    # left branch\n",
    "    if has_left_branch:\n",
    "        net_tmp, last_layer_name = build_simple_block(\n",
    "            incoming_layer, map(lambda s: s % (ix, 1, ''), simple_block_name_pattern),\n",
    "            int(lasagne.layers.get_output_shape(incoming_layer)[1]*4*ratio_n_filter), 1, int(1.0/ratio_size), 0,\n",
    "            nonlin=None)\n",
    "        net.update(net_tmp)\n",
    "        left_tail = net[last_layer_name]\n",
    "\n",
    "    net['res%s' % ix] = ElemwiseSumLayer([left_tail, right_tail], coeffs=1)\n",
    "    net['res%s_relu' % ix] = NonlinearityLayer(net['res%s' % ix], nonlinearity=rectify)\n",
    "\n",
    "    return net, 'res%s_relu' % ix\n",
    "\n",
    "\n",
    "def build_model_my_resnet():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    sub_net, parent_layer_name = build_simple_block(\n",
    "        net['input'], ['conv1', 'bn_conv1', 'conv1_relu'],\n",
    "        64, 7, 2, 3, use_bias=True)\n",
    "    net.update(sub_net)\n",
    "    net['pool1'] = PoolLayer(net[parent_layer_name], pool_size=3, stride=2, pad=0, mode='max', ignore_border=False)\n",
    "    block_size = list('abc')\n",
    "    parent_layer_name = 'pool1'\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1, 1, True, 4, ix='2%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='2%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcd')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='3%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='3%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcdef')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='4%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='4%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abc')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='5%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='5%s' % c)\n",
    "        net.update(sub_net)\n",
    "    net['pool5'] = PoolLayer(net[parent_layer_name], pool_size=7, stride=1, pad=0,\n",
    "                             mode='average_exc_pad', ignore_border=False)\n",
    "    net['dense'] = lasagne.layers.DenseLayer(net['pool5'], num_units=1024)\n",
    "    net['prob'] = lasagne.layers.DenseLayer(net['dense'], num_units=12,\n",
    "                                         nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "class ResNetModel:\n",
    "    def preprocess(self, im):\n",
    "        im = skimage.color.gray2rgb(im)\n",
    "        im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "        im = im[::-1, :, :]\n",
    "        return (im - self._mean_image).astype(np.float32)\n",
    "    \n",
    "    def crop_center(self, img, H=112, W=112):\n",
    "        h,w = img.shape[:2]\n",
    "        hc, wc = h // 2, w // 2\n",
    "        return img[hc - H: hc + H, wc - W : wc + W]\n",
    "    \n",
    "    def augment(self, x, H=224, W=224):\n",
    "        return [x[:H, :W], x[-H:, -W:], x[:H, -W:], x[-H:, :W], self.crop_center(x)]\n",
    "    \n",
    "    def load(self):\n",
    "        weights = pickle.load(open('resnet50_final.pkl', 'rb'))\n",
    "        self._layers = build_model_my_resnet()\n",
    "        lasagne.layers.set_all_param_values(self._layers['prob'], weights['values'])\n",
    "        self._mean_image = weights['mean_image']\n",
    "        inpt = T.tensor4()\n",
    "        self._function = theano.function([inpt], lasagne.layers.get_output(self._layers['prob']\n",
    "                                                                           , inpt, deterministic=True))\n",
    "    def predict(self, X):\n",
    "        X = sum([[self.preprocess(j) for j in self.augment(i)] for i in X], [])\n",
    "        res = self._function(X)\n",
    "        return res.reshape([-1,5,12]).mean(axis=1)\n",
    "    \n",
    "    def unload(self):\n",
    "        del self._layers\n",
    "        del self._function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode=self.mode,\n",
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode=self.mode,\n",
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode=self.mode,\n"
     ]
    }
   ],
   "source": [
    "m = ResNetModel()\n",
    "m.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict([im]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
