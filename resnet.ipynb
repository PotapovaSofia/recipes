{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "from time import time\n",
    "from itertools import chain\n",
    "import skimage.transform\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "\n",
    "\n",
    "def build_simple_block(incoming_layer, names,\n",
    "                       num_filters, filter_size, stride, pad,\n",
    "                       use_bias=False, nonlin=rectify):\n",
    "    \"\"\"Creates stacked Lasagne layers ConvLayer -> BN -> (ReLu)\n",
    "    Parameters:\n",
    "    ----------\n",
    "    incoming_layer : instance of Lasagne layer\n",
    "        Parent layer\n",
    "    names : list of string\n",
    "        Names of the layers in block\n",
    "    num_filters : int\n",
    "        Number of filters in convolution layer\n",
    "    filter_size : int\n",
    "        Size of filters in convolution layer\n",
    "    stride : int\n",
    "        Stride of convolution layer\n",
    "    pad : int\n",
    "        Padding of convolution layer\n",
    "    use_bias : bool\n",
    "        Whether to use bias in conlovution layer\n",
    "    nonlin : function\n",
    "        Nonlinearity type of Nonlinearity layer\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (net, last_layer_name)\n",
    "        net : dict\n",
    "            Dictionary with stacked layers\n",
    "        last_layer_name : string\n",
    "            Last layer name\n",
    "    \"\"\"\n",
    "    names = list(names)\n",
    "    net = []\n",
    "    net.append((\n",
    "            names[0],\n",
    "            ConvLayer(incoming_layer, num_filters, filter_size, stride, pad,\n",
    "                      flip_filters=False, nonlinearity=None) if use_bias\n",
    "            else ConvLayer(incoming_layer, num_filters, filter_size, stride, pad, b=None,\n",
    "                           flip_filters=False, nonlinearity=None)\n",
    "        ))\n",
    "\n",
    "    net.append((\n",
    "            names[1],\n",
    "            BatchNormLayer(net[-1][1])\n",
    "        ))\n",
    "    if nonlin is not None:\n",
    "        net.append((\n",
    "            names[2],\n",
    "            NonlinearityLayer(net[-1][1], nonlinearity=nonlin)\n",
    "        ))\n",
    "\n",
    "    return dict(net), net[-1][0]\n",
    "\n",
    "\n",
    "def build_residual_block(incoming_layer, ratio_n_filter=1.0, ratio_size=1.0, has_left_branch=False,\n",
    "                         upscale_factor=4, ix=''):\n",
    "    \"\"\"Creates two-branch residual block\n",
    "    Parameters:\n",
    "    ----------\n",
    "    incoming_layer : instance of Lasagne layer\n",
    "        Parent layer\n",
    "    ratio_n_filter : float\n",
    "        Scale factor of filter bank at the input of residual block\n",
    "    ratio_size : float\n",
    "        Scale factor of filter size\n",
    "    has_left_branch : bool\n",
    "        if True, then left branch contains simple block\n",
    "    upscale_factor : float\n",
    "        Scale factor of filter bank at the output of residual block\n",
    "    ix : int\n",
    "        Id of residual block\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (net, last_layer_name)\n",
    "        net : dict\n",
    "            Dictionary with stacked layers\n",
    "        last_layer_name : string\n",
    "            Last layer name\n",
    "    \"\"\"\n",
    "    simple_block_name_pattern = ['res%s_branch%i%s', 'bn%s_branch%i%s', 'res%s_branch%i%s_relu']\n",
    "\n",
    "    net = {}\n",
    "\n",
    "    # right branch\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        incoming_layer, map(lambda s: s % (ix, 2, 'a'), simple_block_name_pattern),\n",
    "        int(lasagne.layers.get_output_shape(incoming_layer)[1]*ratio_n_filter), 1, int(1.0/ratio_size), 0)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'b'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1], 3, 1, 1)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'c'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1]*upscale_factor, 1, 1, 0,\n",
    "        nonlin=None)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    right_tail = net[last_layer_name]\n",
    "    left_tail = incoming_layer\n",
    "\n",
    "    # left branch\n",
    "    if has_left_branch:\n",
    "        net_tmp, last_layer_name = build_simple_block(\n",
    "            incoming_layer, map(lambda s: s % (ix, 1, ''), simple_block_name_pattern),\n",
    "            int(lasagne.layers.get_output_shape(incoming_layer)[1]*4*ratio_n_filter), 1, int(1.0/ratio_size), 0,\n",
    "            nonlin=None)\n",
    "        net.update(net_tmp)\n",
    "        left_tail = net[last_layer_name]\n",
    "\n",
    "    net['res%s' % ix] = ElemwiseSumLayer([left_tail, right_tail], coeffs=1)\n",
    "    net['res%s_relu' % ix] = NonlinearityLayer(net['res%s' % ix], nonlinearity=rectify)\n",
    "\n",
    "    return net, 'res%s_relu' % ix\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    sub_net, parent_layer_name = build_simple_block(\n",
    "        net['input'], ['conv1', 'bn_conv1', 'conv1_relu'],\n",
    "        64, 7, 2, 3, use_bias=True)\n",
    "    net.update(sub_net)\n",
    "    net['pool1'] = PoolLayer(net[parent_layer_name], pool_size=3, stride=2, pad=0, mode='max', ignore_border=False)\n",
    "    block_size = list('abc')\n",
    "    parent_layer_name = 'pool1'\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1, 1, True, 4, ix='2%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='2%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcd')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='3%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='3%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcdef')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='4%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='4%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abc')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='5%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='5%s' % c)\n",
    "        net.update(sub_net)\n",
    "    net['pool5'] = PoolLayer(net[parent_layer_name], pool_size=7, stride=1, pad=0,\n",
    "                             mode='average_exc_pad', ignore_border=False)\n",
    "    net['fc1000'] = DenseLayer(net['pool5'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc1000'], nonlinearity=softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = pickle.load(open('resnet50.pkl', 'rb'), encoding='latin1')\n",
    "lasagne.layers.set_all_param_values(model['prob'], weights['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "newmodel = {}\n",
    "newmodel['dense1'] = DenseLayer(model['pool5'], 1000)\n",
    "newmodel['dense2'] = DenseLayer(newmodel['dense1'], 1000)\n",
    "newmodel['prob'] = DenseLayer(newmodel['dense2'], 101, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, W, W, W, W, W, W, W, W, W]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = sum([x.get_params(trainable=True) for x in newmodel.values()], [])\n",
    "weights.extend(sum([x.get_params(trainablweightse=True) for k, x in model.items() if k[:4] == 'res5'], []))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode=self.mode,\n",
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode=self.mode,\n",
      "/home/ubuntu/env/src/lasagne/lasagne/layers/pool.py:266: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode=self.mode,\n"
     ]
    }
   ],
   "source": [
    "netinput = T.tensor4()\n",
    "netoutput = T.matrix()\n",
    "nettarget = T.ivector()\n",
    "\n",
    "pred = lasagne.layers.get_output(newmodel['prob'], netinput)\n",
    "pred_det = lasagne.layers.get_output(newmodel['prob'], netinput, deterministic=True)\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(pred, nettarget).mean()\n",
    "final_acc = lasagne.objectives.categorical_accuracy(pred_det, nettarget).mean()\n",
    "\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = theano.function([netinput, nettarget], loss, updates=updates)\n",
    "val = theano.function([netinput, nettarget], final_acc)\n",
    "pred = theano.function([netinput], pred_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_reader(d, firstchar):\n",
    "    for filename in glob(d + '/' + firstchar + '*.avi'):\n",
    "        yield imageio.get_reader(filename), filename[len(d) + 1:]\n",
    "\n",
    "def random_frames(it, cnt=10):\n",
    "    for r, fname in it:\n",
    "        try:\n",
    "            yield [(r.get_data(random.randint(0, r.get_length() - 1)), fname) for _ in range(cnt)]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def remove_batches(it):\n",
    "    for r in it:\n",
    "        for q in r:\n",
    "            yield q\n",
    "\n",
    "def resizer(it):\n",
    "    for r, c in it:\n",
    "        im = skimage.transform.resize(r, (224, 224), mode='constant')\n",
    "        im = im.swapaxes(2, 1).swapaxes(1, 0)\n",
    "        yield im, c\n",
    "\n",
    "def replace_filename_with_class(it, df):\n",
    "    for r, fname in it:\n",
    "        yield r, df[df.filename==fname].classnum.values[0]\n",
    "\n",
    "def local_shuffler(it, size):\n",
    "    s = []\n",
    "    for i in it:\n",
    "        s.append(i)\n",
    "        if len(s) > size:\n",
    "            yield s.pop(random.randint(0, len(s) - 1))\n",
    "    while len(s) > size:\n",
    "        yield s.pop(random.randint(0, len(s) - 1))\n",
    "    \n",
    "\n",
    "def batcher(it, size):\n",
    "    batchx, batchy = [], []\n",
    "    for x, y in it:\n",
    "        batchx.append(x)\n",
    "        batchy.append(y)\n",
    "        if len(batchx) == size:\n",
    "            yield np.array(batchx).astype(np.float32), batchy\n",
    "            batchx, batchy = [], []\n",
    "    if len(batchy):\n",
    "        yield np.array(batchx).astype(np.float32), batchy\n",
    "\n",
    "def threaded_generator(generator, num_cached=3):\n",
    "    # this code is written by jan Schluter\n",
    "    # copied from https://github.com/benanne/Lasagne/issues/12\n",
    "    queue = Queue(maxsize=num_cached)\n",
    "    sentinel = object()  # guaranteed unique reference\n",
    "\n",
    "    # define producer (putting items into queue)\n",
    "    def producer():\n",
    "        for item in generator:\n",
    "            queue.put(item)\n",
    "        queue.put(sentinel)\n",
    "\n",
    "    # start producer (in a background thread)\n",
    "    thread = threading.Thread(target=producer)\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "    # run as consumer (read items from queue, in current thread)\n",
    "    item = queue.get()\n",
    "    while item is not sentinel:\n",
    "        yield item\n",
    "        queue.task_done()\n",
    "        item = queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_log, val_log = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [08:29, 26.83s/it]"
     ]
    }
   ],
   "source": [
    "for ep in range(1):\n",
    "    t = time()\n",
    "    \n",
    "    err = 0.\n",
    "    batches = 0\n",
    "    generator = threaded_generator(batcher(local_shuffler(\n",
    "        replace_filename_with_class(\n",
    "        resizer(\n",
    "        remove_batches(\n",
    "        random_frames(\n",
    "            data_reader('action-recognition-train', '[1-9]'),\n",
    "            cnt=1))), train_df), size=100), size=100))\n",
    "    for bx, by in tqdm(generator):\n",
    "        err += train(bx, by)\n",
    "        batches += 1\n",
    "    train_log.append(err / batches)\n",
    "    err = 0.\n",
    "    batches = 0\n",
    "    generator = threaded_generator(batcher(\n",
    "        replace_filename_with_class(\n",
    "        resizer(\n",
    "        remove_batches(\n",
    "        random_frames(\n",
    "            data_reader('action-recognition-train', '0'),\n",
    "            cnt=1))), train_df), size=200))\n",
    "    for bx, by in tqdm(generator):\n",
    "        err += val(bx, by)\n",
    "        batches += 1\n",
    "    val_log.append(err / batches)\n",
    "    \n",
    "    print('epoch: {}\\ttook: {}\\ttrain_loss: {}\\tval_loss: {}'.format(ep, time() - t, train_log[-1], val_log[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [01:55, 115.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [03:52, 116.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [05:47, 115.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [09:34, 114.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [11:29, 114.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [13:23, 114.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [15:18, 114.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [17:12, 114.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [19:08, 115.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [21:04, 115.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [22:58, 114.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [24:53, 114.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [26:48, 114.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [28:44, 115.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [30:39, 115.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [32:36, 115.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [34:31, 115.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [35:43, 102.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "cnt_means = 4\n",
    "generator = batcher(\n",
    "        resizer(\n",
    "        remove_batches(\n",
    "        random_frames(\n",
    "            data_reader('action-recognition-test', ''),\n",
    "            cnt=cnt_means))), size=200 * cnt_means)\n",
    "for bx, by in tqdm(generator):\n",
    "    p = pred(bx).reshape([-1, cnt_means, 101]).mean(axis=1).argmax(axis=1)\n",
    "    for fname, res in zip(by[::cnt_means], p):\n",
    "        result[fname] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('result.csv', 'w') as f:\n",
    "    f.write('filename,classnum\\n')\n",
    "    for fname, cls in result.items():\n",
    "        f.write(fname + ',' + str(cls) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(lasagne.layers.get_all_param_values(newmodel['prob']), open('weights.pcl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(newmodel['prob'], pickle.loads(open('weights.pcl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
